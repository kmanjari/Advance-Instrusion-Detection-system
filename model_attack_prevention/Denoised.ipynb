{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open('Adv_sample.pkl','rb') as f:\n",
    "    X_adv=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.0035203 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.98855877, 0.15069449, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11555127, 0.11555127, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23516, 36)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original data\n",
    "with open('X_train_scaled.pkl','rb') as X_tr:\n",
    "    X_train_scaled=pickle.load(X_tr)\n",
    "with open('X_test_scaled.pkl','rb') as X_te:\n",
    "    X_test_scaled=pickle.load(X_te)\n",
    "with open('y_train.pkl','rb') as y_tr:\n",
    "    Y_train=pickle.load(y_tr)\n",
    "with open('y_test.pkl','rb') as y_te:\n",
    "    Y_test=pickle.load(y_te)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 36) (125000,) (23516, 36) (23516,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape,Y_train.shape,X_test_scaled.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         normal\n",
       "2         normal\n",
       "3         attack\n",
       "4         normal\n",
       "5         normal\n",
       "6         attack\n",
       "7         attack\n",
       "8         attack\n",
       "9         attack\n",
       "10        attack\n",
       "11        attack\n",
       "12        attack\n",
       "13        normal\n",
       "14        attack\n",
       "15        attack\n",
       "16        attack\n",
       "17        normal\n",
       "18        attack\n",
       "19        normal\n",
       "20        normal\n",
       "21        attack\n",
       "22        attack\n",
       "23        normal\n",
       "24        normal\n",
       "25        attack\n",
       "26        normal\n",
       "27        attack\n",
       "28        normal\n",
       "29        normal\n",
       "30        normal\n",
       "           ...  \n",
       "124971    normal\n",
       "124972    normal\n",
       "124973    normal\n",
       "124974    attack\n",
       "124975    attack\n",
       "124976    normal\n",
       "124977    normal\n",
       "124978    attack\n",
       "124979    normal\n",
       "124980    attack\n",
       "124981    normal\n",
       "124982    attack\n",
       "124983    attack\n",
       "124984    normal\n",
       "124985    normal\n",
       "124986    attack\n",
       "124987    attack\n",
       "124988    normal\n",
       "124989    attack\n",
       "124990    attack\n",
       "124991    attack\n",
       "124992    attack\n",
       "124993    normal\n",
       "124994    attack\n",
       "124995    normal\n",
       "124996    normal\n",
       "124997    attack\n",
       "124998    normal\n",
       "124999    normal\n",
       "125000    normal\n",
       "Name: unknown1, Length: 125000, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bool(x):\n",
    "    if(x == \"attack\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train.apply(convert_bool))\n",
    "Y_test=np.array(Y_test.apply(convert_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125000,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide X_adv in two parts X_train and X_test             Divide X_test_scaled in two parts y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_adv, X_test_scaled, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12031003, 0.11246372, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.28911734, 0.7131561 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.17635958, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07755633, 0.9899838 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.00340742,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12031003, 0.11246372, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.28911734, 0.7131561 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.17635958, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07755634, 0.98998381, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.00340742,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18812, 36) (18812, 36) (4704, 36) (4704, 36)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for de-noising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense \n",
    "from keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding_dim = 10\n",
    "input_dim = X_adv.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model for encoding adversarial input\n",
    "def auto_encoder_model(input_dim) :\n",
    "    \n",
    "    input_layer = Input(shape = (input_dim,))\n",
    "    \n",
    "    encoder = Dense(18, activation = 'relu')(input_layer)\n",
    "    #encoder = Dense(12, activation=\"relu\")(encoder)\n",
    "    #encoder = Dense(9, activation=\"relu\")(encoder)\n",
    "    encoder = Dense(3, activation=\"relu\")(encoder)\n",
    "    \n",
    "    #decoder = Dense(6 ,activation='relu')(encoder)\n",
    "    #decoder = Dense(9, activation='relu')(encoder)\n",
    "    decoder = Dense(18, activation='relu')(encoder)\n",
    "    decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "    \n",
    "    autoencoder = Model(inputs=input_layer,outputs= decoder)\n",
    "    \n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    \n",
    "    autoencoder.summary()\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 18)                666       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 3)                 57        \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 18)                72        \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 36)                684       \n",
      "=================================================================\n",
      "Total params: 1,479\n",
      "Trainable params: 1,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model for encoder\n",
    "denoiser = auto_encoder_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18812 samples, validate on 4704 samples\n",
      "Epoch 1/100\n",
      "18812/18812 [==============================] - 1s 74us/step - loss: 4.4568e-04 - acc: 0.9296 - val_loss: 5.1532e-04 - val_acc: 0.9154\n",
      "Epoch 2/100\n",
      "18812/18812 [==============================] - 1s 72us/step - loss: 4.4383e-04 - acc: 0.9303 - val_loss: 5.3015e-04 - val_acc: 0.9624\n",
      "Epoch 3/100\n",
      "18812/18812 [==============================] - 1s 75us/step - loss: 4.3639e-04 - acc: 0.9306 - val_loss: 5.0204e-04 - val_acc: 0.9339\n",
      "Epoch 4/100\n",
      "18812/18812 [==============================] - 2s 93us/step - loss: 4.3467e-04 - acc: 0.9280 - val_loss: 5.0122e-04 - val_acc: 0.9247\n",
      "Epoch 5/100\n",
      "18812/18812 [==============================] - 2s 81us/step - loss: 4.3017e-04 - acc: 0.9287 - val_loss: 4.9923e-04 - val_acc: 0.9447\n",
      "Epoch 6/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 4.2973e-04 - acc: 0.9289 - val_loss: 4.9009e-04 - val_acc: 0.9449\n",
      "Epoch 7/100\n",
      "18812/18812 [==============================] - 1s 61us/step - loss: 4.2678e-04 - acc: 0.9284 - val_loss: 4.9732e-04 - val_acc: 0.9041\n",
      "Epoch 8/100\n",
      "18812/18812 [==============================] - 2s 129us/step - loss: 4.2406e-04 - acc: 0.9294 - val_loss: 4.8794e-04 - val_acc: 0.9154\n",
      "Epoch 9/100\n",
      "18812/18812 [==============================] - 2s 94us/step - loss: 4.2121e-04 - acc: 0.9296 - val_loss: 4.8527e-04 - val_acc: 0.9075\n",
      "Epoch 10/100\n",
      "18812/18812 [==============================] - 2s 90us/step - loss: 4.1751e-04 - acc: 0.9282 - val_loss: 4.8311e-04 - val_acc: 0.9233\n",
      "Epoch 11/100\n",
      "18812/18812 [==============================] - 2s 111us/step - loss: 4.1698e-04 - acc: 0.9253 - val_loss: 4.8530e-04 - val_acc: 0.9517\n",
      "Epoch 12/100\n",
      "18812/18812 [==============================] - 2s 100us/step - loss: 4.1418e-04 - acc: 0.9271 - val_loss: 4.7337e-04 - val_acc: 0.9003\n",
      "Epoch 13/100\n",
      "18812/18812 [==============================] - 2s 85us/step - loss: 4.1155e-04 - acc: 0.9276 - val_loss: 4.7861e-04 - val_acc: 0.9124\n",
      "Epoch 14/100\n",
      "18812/18812 [==============================] - 2s 81us/step - loss: 4.1169e-04 - acc: 0.9264 - val_loss: 4.6570e-04 - val_acc: 0.9269\n",
      "Epoch 15/100\n",
      "18812/18812 [==============================] - 2s 122us/step - loss: 4.0776e-04 - acc: 0.9266 - val_loss: 4.7136e-04 - val_acc: 0.9328\n",
      "Epoch 16/100\n",
      "18812/18812 [==============================] - 2s 97us/step - loss: 4.0806e-04 - acc: 0.9279 - val_loss: 4.6312e-04 - val_acc: 0.9237\n",
      "Epoch 17/100\n",
      "18812/18812 [==============================] - 2s 96us/step - loss: 4.0038e-04 - acc: 0.9272 - val_loss: 4.6096e-04 - val_acc: 0.9313\n",
      "Epoch 18/100\n",
      "18812/18812 [==============================] - 2s 80us/step - loss: 4.0296e-04 - acc: 0.9289 - val_loss: 4.5789e-04 - val_acc: 0.9048\n",
      "Epoch 19/100\n",
      "18812/18812 [==============================] - 2s 84us/step - loss: 3.9743e-04 - acc: 0.9275 - val_loss: 4.5365e-04 - val_acc: 0.9109\n",
      "Epoch 20/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.9776e-04 - acc: 0.9264 - val_loss: 4.5281e-04 - val_acc: 0.9301\n",
      "Epoch 21/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.9628e-04 - acc: 0.9270 - val_loss: 4.6112e-04 - val_acc: 0.9337\n",
      "Epoch 22/100\n",
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.9246e-04 - acc: 0.9260 - val_loss: 4.5567e-04 - val_acc: 0.9452\n",
      "Epoch 23/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.9301e-04 - acc: 0.9260 - val_loss: 4.6480e-04 - val_acc: 0.9522\n",
      "Epoch 24/100\n",
      "18812/18812 [==============================] - 2s 80us/step - loss: 3.9068e-04 - acc: 0.9284 - val_loss: 4.5456e-04 - val_acc: 0.9520\n",
      "Epoch 25/100\n",
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.8746e-04 - acc: 0.9246 - val_loss: 4.5086e-04 - val_acc: 0.9452\n",
      "Epoch 26/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.8873e-04 - acc: 0.9253 - val_loss: 4.6034e-04 - val_acc: 0.9452\n",
      "Epoch 27/100\n",
      "18812/18812 [==============================] - 1s 77us/step - loss: 3.8495e-04 - acc: 0.9262 - val_loss: 4.4811e-04 - val_acc: 0.9469\n",
      "Epoch 28/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.8600e-04 - acc: 0.9235 - val_loss: 4.4348e-04 - val_acc: 0.9324\n",
      "Epoch 29/100\n",
      "18812/18812 [==============================] - 2s 81us/step - loss: 3.8302e-04 - acc: 0.9295 - val_loss: 4.5273e-04 - val_acc: 0.8992\n",
      "Epoch 30/100\n",
      "18812/18812 [==============================] - 1s 77us/step - loss: 3.8173e-04 - acc: 0.9275 - val_loss: 4.5057e-04 - val_acc: 0.9388\n",
      "Epoch 31/100\n",
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.8070e-04 - acc: 0.9275 - val_loss: 4.3909e-04 - val_acc: 0.9420\n",
      "Epoch 32/100\n",
      "18812/18812 [==============================] - 2s 83us/step - loss: 3.7939e-04 - acc: 0.9275 - val_loss: 4.4779e-04 - val_acc: 0.9298\n",
      "Epoch 33/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.8120e-04 - acc: 0.9258 - val_loss: 4.4838e-04 - val_acc: 0.9267\n",
      "Epoch 34/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.7786e-04 - acc: 0.9249 - val_loss: 4.5005e-04 - val_acc: 0.9171\n",
      "Epoch 35/100\n",
      "18812/18812 [==============================] - 2s 85us/step - loss: 3.7670e-04 - acc: 0.9280 - val_loss: 4.5588e-04 - val_acc: 0.9396\n",
      "Epoch 36/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.7685e-04 - acc: 0.9287 - val_loss: 4.4076e-04 - val_acc: 0.9097\n",
      "Epoch 37/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.7471e-04 - acc: 0.9271 - val_loss: 4.4844e-04 - val_acc: 0.8833\n",
      "Epoch 38/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.7342e-04 - acc: 0.9269 - val_loss: 4.3901e-04 - val_acc: 0.9384\n",
      "Epoch 39/100\n",
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.7429e-04 - acc: 0.9262 - val_loss: 4.5027e-04 - val_acc: 0.9594\n",
      "Epoch 40/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.7316e-04 - acc: 0.9286 - val_loss: 4.4239e-04 - val_acc: 0.9260\n",
      "Epoch 41/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.7117e-04 - acc: 0.9253 - val_loss: 4.5277e-04 - val_acc: 0.8963\n",
      "Epoch 42/100\n",
      "18812/18812 [==============================] - 2s 83us/step - loss: 3.6930e-04 - acc: 0.9297 - val_loss: 4.3944e-04 - val_acc: 0.9254\n",
      "Epoch 43/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.7055e-04 - acc: 0.9282 - val_loss: 4.5744e-04 - val_acc: 0.8982\n",
      "Epoch 44/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.6987e-04 - acc: 0.9264 - val_loss: 4.3088e-04 - val_acc: 0.9377\n",
      "Epoch 45/100\n",
      "18812/18812 [==============================] - 2s 83us/step - loss: 3.6697e-04 - acc: 0.9272 - val_loss: 4.2856e-04 - val_acc: 0.9413\n",
      "Epoch 46/100\n",
      "18812/18812 [==============================] - 1s 77us/step - loss: 3.6563e-04 - acc: 0.9295 - val_loss: 4.3639e-04 - val_acc: 0.9332\n",
      "Epoch 47/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.6822e-04 - acc: 0.9290 - val_loss: 4.4654e-04 - val_acc: 0.8786\n",
      "Epoch 48/100\n",
      "18812/18812 [==============================] - ETA: 0s - loss: 3.6735e-04 - acc: 0.928 - 1s 79us/step - loss: 3.6810e-04 - acc: 0.9281 - val_loss: 4.3487e-04 - val_acc: 0.9258\n",
      "Epoch 49/100\n",
      "18812/18812 [==============================] - 2s 88us/step - loss: 3.6460e-04 - acc: 0.9261 - val_loss: 4.4227e-04 - val_acc: 0.9328\n",
      "Epoch 50/100\n",
      "18812/18812 [==============================] - 2s 81us/step - loss: 3.6675e-04 - acc: 0.9262 - val_loss: 4.2928e-04 - val_acc: 0.9262\n",
      "Epoch 51/100\n",
      "18812/18812 [==============================] - 2s 91us/step - loss: 3.6461e-04 - acc: 0.9256 - val_loss: 4.3290e-04 - val_acc: 0.9239\n",
      "Epoch 52/100\n",
      "18812/18812 [==============================] - 2s 93us/step - loss: 3.6292e-04 - acc: 0.9270 - val_loss: 4.2609e-04 - val_acc: 0.9309\n",
      "Epoch 53/100\n",
      "18812/18812 [==============================] - 2s 83us/step - loss: 3.6012e-04 - acc: 0.9292 - val_loss: 4.3440e-04 - val_acc: 0.9328\n",
      "Epoch 54/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.6190e-04 - acc: 0.9232 - val_loss: 4.2560e-04 - val_acc: 0.9335\n",
      "Epoch 55/100\n",
      "18812/18812 [==============================] - 2s 97us/step - loss: 3.6194e-04 - acc: 0.9243 - val_loss: 4.2680e-04 - val_acc: 0.9156\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.6060e-04 - acc: 0.9261 - val_loss: 4.5011e-04 - val_acc: 0.9447\n",
      "Epoch 57/100\n",
      "18812/18812 [==============================] - 2s 84us/step - loss: 3.6149e-04 - acc: 0.9273 - val_loss: 4.2727e-04 - val_acc: 0.9116\n",
      "Epoch 58/100\n",
      "18812/18812 [==============================] - 2s 90us/step - loss: 3.5900e-04 - acc: 0.9262 - val_loss: 4.2669e-04 - val_acc: 0.9384\n",
      "Epoch 59/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.5767e-04 - acc: 0.9274 - val_loss: 4.3247e-04 - val_acc: 0.9279\n",
      "Epoch 60/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.5815e-04 - acc: 0.9272 - val_loss: 4.2895e-04 - val_acc: 0.9403\n",
      "Epoch 61/100\n",
      "18812/18812 [==============================] - 2s 85us/step - loss: 3.5730e-04 - acc: 0.9237 - val_loss: 4.2798e-04 - val_acc: 0.9233\n",
      "Epoch 62/100\n",
      "18812/18812 [==============================] - 2s 80us/step - loss: 3.5654e-04 - acc: 0.9281 - val_loss: 4.2428e-04 - val_acc: 0.9296\n",
      "Epoch 63/100\n",
      "18812/18812 [==============================] - 2s 80us/step - loss: 3.5737e-04 - acc: 0.9271 - val_loss: 4.3794e-04 - val_acc: 0.9156\n",
      "Epoch 64/100\n",
      "18812/18812 [==============================] - 2s 95us/step - loss: 3.5624e-04 - acc: 0.9240 - val_loss: 4.2759e-04 - val_acc: 0.9332\n",
      "Epoch 65/100\n",
      "18812/18812 [==============================] - 2s 81us/step - loss: 3.5578e-04 - acc: 0.9258 - val_loss: 4.2661e-04 - val_acc: 0.9452\n",
      "Epoch 66/100\n",
      "18812/18812 [==============================] - 2s 81us/step - loss: 3.5452e-04 - acc: 0.9249 - val_loss: 4.2885e-04 - val_acc: 0.9279\n",
      "Epoch 67/100\n",
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.5357e-04 - acc: 0.9255 - val_loss: 4.3109e-04 - val_acc: 0.9313\n",
      "Epoch 68/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.5210e-04 - acc: 0.9266 - val_loss: 4.2900e-04 - val_acc: 0.9075\n",
      "Epoch 69/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.5348e-04 - acc: 0.9241 - val_loss: 4.2902e-04 - val_acc: 0.9324\n",
      "Epoch 70/100\n",
      "18812/18812 [==============================] - 2s 80us/step - loss: 3.5319e-04 - acc: 0.9258 - val_loss: 4.2202e-04 - val_acc: 0.9301\n",
      "Epoch 71/100\n",
      "18812/18812 [==============================] - 2s 83us/step - loss: 3.4999e-04 - acc: 0.9245 - val_loss: 4.2515e-04 - val_acc: 0.9279\n",
      "Epoch 72/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.5099e-04 - acc: 0.9287 - val_loss: 4.2771e-04 - val_acc: 0.9579\n",
      "Epoch 73/100\n",
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.5030e-04 - acc: 0.9246 - val_loss: 4.3830e-04 - val_acc: 0.9354\n",
      "Epoch 74/100\n",
      "18812/18812 [==============================] - 2s 87us/step - loss: 3.4866e-04 - acc: 0.9235 - val_loss: 4.2000e-04 - val_acc: 0.9024\n",
      "Epoch 75/100\n",
      "18812/18812 [==============================] - 2s 106us/step - loss: 3.4972e-04 - acc: 0.9233 - val_loss: 4.3134e-04 - val_acc: 0.9126\n",
      "Epoch 76/100\n",
      "18812/18812 [==============================] - 2s 133us/step - loss: 3.5009e-04 - acc: 0.9254 - val_loss: 4.2451e-04 - val_acc: 0.9411\n",
      "Epoch 77/100\n",
      "18812/18812 [==============================] - 2s 98us/step - loss: 3.4808e-04 - acc: 0.9260 - val_loss: 4.2372e-04 - val_acc: 0.9328\n",
      "Epoch 78/100\n",
      "18812/18812 [==============================] - 2s 93us/step - loss: 3.5107e-04 - acc: 0.9221 - val_loss: 4.3124e-04 - val_acc: 0.9258\n",
      "Epoch 79/100\n",
      "18812/18812 [==============================] - 2s 107us/step - loss: 3.4842e-04 - acc: 0.9284 - val_loss: 4.1722e-04 - val_acc: 0.9233\n",
      "Epoch 80/100\n",
      "18812/18812 [==============================] - 2s 120us/step - loss: 3.4756e-04 - acc: 0.9243 - val_loss: 4.3447e-04 - val_acc: 0.9213\n",
      "Epoch 81/100\n",
      "18812/18812 [==============================] - 2s 99us/step - loss: 3.4879e-04 - acc: 0.9239 - val_loss: 4.2845e-04 - val_acc: 0.9052\n",
      "Epoch 82/100\n",
      "18812/18812 [==============================] - 2s 96us/step - loss: 3.4715e-04 - acc: 0.9255 - val_loss: 4.4180e-04 - val_acc: 0.8667\n",
      "Epoch 83/100\n",
      "18812/18812 [==============================] - 2s 90us/step - loss: 3.4551e-04 - acc: 0.9253 - val_loss: 4.1392e-04 - val_acc: 0.9343\n",
      "Epoch 84/100\n",
      "18812/18812 [==============================] - 2s 81us/step - loss: 3.4402e-04 - acc: 0.9275 - val_loss: 4.3166e-04 - val_acc: 0.9086\n",
      "Epoch 85/100\n",
      "18812/18812 [==============================] - 2s 87us/step - loss: 3.4545e-04 - acc: 0.9239 - val_loss: 4.3750e-04 - val_acc: 0.9413\n",
      "Epoch 86/100\n",
      "18812/18812 [==============================] - 2s 89us/step - loss: 3.4507e-04 - acc: 0.9240 - val_loss: 4.4825e-04 - val_acc: 0.9356\n",
      "Epoch 87/100\n",
      "18812/18812 [==============================] - 2s 84us/step - loss: 3.4620e-04 - acc: 0.9255 - val_loss: 4.5457e-04 - val_acc: 0.9573\n",
      "Epoch 88/100\n",
      "18812/18812 [==============================] - 2s 99us/step - loss: 3.4562e-04 - acc: 0.9244 - val_loss: 4.2930e-04 - val_acc: 0.9301\n",
      "Epoch 89/100\n",
      "18812/18812 [==============================] - 2s 96us/step - loss: 3.4373e-04 - acc: 0.9266 - val_loss: 4.2763e-04 - val_acc: 0.8754\n",
      "Epoch 90/100\n",
      "18812/18812 [==============================] - 2s 83us/step - loss: 3.4478e-04 - acc: 0.9253 - val_loss: 4.1480e-04 - val_acc: 0.9511\n",
      "Epoch 91/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.4376e-04 - acc: 0.9271 - val_loss: 4.1905e-04 - val_acc: 0.9464\n",
      "Epoch 92/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.4074e-04 - acc: 0.9272 - val_loss: 4.1404e-04 - val_acc: 0.9483\n",
      "Epoch 93/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.4035e-04 - acc: 0.9268 - val_loss: 4.1918e-04 - val_acc: 0.9137\n",
      "Epoch 94/100\n",
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.4142e-04 - acc: 0.9252 - val_loss: 4.3146e-04 - val_acc: 0.9216\n",
      "Epoch 95/100\n",
      "18812/18812 [==============================] - 1s 76us/step - loss: 3.4088e-04 - acc: 0.9279 - val_loss: 4.3017e-04 - val_acc: 0.9080\n",
      "Epoch 96/100\n",
      "18812/18812 [==============================] - 1s 79us/step - loss: 3.4176e-04 - acc: 0.9242 - val_loss: 4.3340e-04 - val_acc: 0.9228\n",
      "Epoch 97/100\n",
      "18812/18812 [==============================] - 2s 85us/step - loss: 3.3844e-04 - acc: 0.9277 - val_loss: 4.1916e-04 - val_acc: 0.9196\n",
      "Epoch 98/100\n",
      "18812/18812 [==============================] - 2s 80us/step - loss: 3.3915e-04 - acc: 0.9246 - val_loss: 4.1651e-04 - val_acc: 0.9241\n",
      "Epoch 99/100\n",
      "18812/18812 [==============================] - 1s 78us/step - loss: 3.3911e-04 - acc: 0.9267 - val_loss: 4.1972e-04 - val_acc: 0.9379\n",
      "Epoch 100/100\n",
      "18812/18812 [==============================] - 2s 82us/step - loss: 3.3549e-04 - acc: 0.9295 - val_loss: 4.2367e-04 - val_acc: 0.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23110e48>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser.fit(X_train, y_train, epochs=100, batch_size=50, validation_data = (X_test, y_test), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting original test_scaled\n",
    "X_adv_denoised=denoiser.predict(X_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.0035203 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.98855877, 0.15069449, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11555127, 0.11555127, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.0035203 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.98855875, 0.15069449, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11555127, 0.11555127, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01216458, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.9982251 , 0.15714976, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.13139431, 0.12650296, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adv_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23516, 36)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adv_denoised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('X_adv_denoiser.pkl','wb') as f:\n",
    "    pickle.dump(X_adv_denoised,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
